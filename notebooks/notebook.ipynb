{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    BertModel,\n",
    "    BertTokenizer,\n",
    ")\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "from typing import Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: NVIDIA GeForce RTX 4070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"No GPU available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Force CUDA device if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"Preprocess\"\"\"\n",
    "\n",
    "    stopwords = []\n",
    "    extra_stopwords = [\n",
    "        # 'LINK',\n",
    "        # 'USER',\n",
    "        \"RT\",\n",
    "        \"@\",\n",
    "    ]\n",
    "    stopwords = list(extra_stopwords)\n",
    "\n",
    "    pattern = r\"(?i)\\b(?:\" + \"|\".join(re.escape(word) for word in stopwords) + r\")\\b\"\n",
    "    text = re.sub(pattern, \"\", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_1b(train_file, preprocessing: bool, unique_labels):\n",
    "    \"\"\"Read data for the task 1B\"\"\"\n",
    "    train_texts = []\n",
    "    train_labels = []\n",
    "    train_types = []\n",
    "\n",
    "    mlb = MultiLabelBinarizer(classes=list(unique_labels))\n",
    "\n",
    "    train_ids = []\n",
    "\n",
    "    with jsonlines.open(train_file) as train_f:\n",
    "        for obj in tqdm(train_f, desc=\"Processing\", unit=\"line\"):\n",
    "            doc_id = str(obj[\"id\"])\n",
    "            labels = obj[\"labels\"]\n",
    "            labels = mlb.fit_transform([set(labels)]).tolist()[0]\n",
    "            train_labels.append(labels)\n",
    "\n",
    "            train_texts.append(\n",
    "                preprocess(obj[\"text\"]) if preprocessing else obj[\"text\"]\n",
    "            )\n",
    "            types = 1 if obj[\"type\"] == \"tweet\" else 0\n",
    "            train_types.append(types)\n",
    "\n",
    "            train_ids.append(obj[\"id\"])\n",
    "\n",
    "    return train_texts, train_labels, train_types, train_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and loss function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultitaskClassification(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.config = config\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout\n",
    "            if config.classifier_dropout is not None\n",
    "            else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.classifier2 = nn.Linear(config.hidden_size, 2)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        labels_types: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "        logits2 = self.classifier2(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (\n",
    "                    labels.dtype == torch.long or labels.dtype == torch.int\n",
    "                ):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        ), logits2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertMultilabelClassifier:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_path,\n",
    "        num_classes,\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    ):\n",
    "        self.model = BertForMultitaskClassification.from_pretrained(\n",
    "            model_path,\n",
    "            num_labels=num_classes,\n",
    "            problem_type=\"multi_label_classification\",\n",
    "        )\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "        self.device = torch.device(device)\n",
    "        self.model.to(self.device)\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def tokenize_texts(self, texts):\n",
    "        encoded_texts = self.tokenizer(\n",
    "            texts, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = encoded_texts[\"input_ids\"].to(self.device)\n",
    "        attention_mask = encoded_texts[\"attention_mask\"].to(self.device)\n",
    "\n",
    "        return input_ids, attention_mask\n",
    "\n",
    "    def train(\n",
    "        self, texts, labels, labels_types, batch_size=8, epochs=4, learning_rate=2e-5\n",
    "    ):\n",
    "        input_ids, attention_mask = self.tokenize_texts(texts)\n",
    "\n",
    "        labels = torch.tensor(labels).to(torch.float).to(self.device)\n",
    "        labels_types = torch.tensor(labels_types).to(torch.long).to(self.device)\n",
    "\n",
    "        dataset = TensorDataset(input_ids, attention_mask, labels, labels_types)\n",
    "\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.model.parameters(), lr=learning_rate)\n",
    "        loss_function = FocalLoss()\n",
    "        # loss_function = BCEWithLogitsLoss()\n",
    "        for epoch in tqdm(range(epochs), desc=\"Running epoch \"):\n",
    "            self.model.train()\n",
    "            total_loss = 0.0\n",
    "            for batch in dataloader:\n",
    "                batch = tuple(t.to(self.device) for t in batch)\n",
    "                input_ids, attention_mask, labels, labels_types = batch\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs, logits2 = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels.float(),\n",
    "                    labels_types=labels_types.float(),\n",
    "                )\n",
    "                logits = outputs.logits\n",
    "                # logits = torch.tensor(logits).to(torch.long).to(self.device)\n",
    "\n",
    "                loss1 = (\n",
    "                    outputs.loss\n",
    "                )  # loss_function(logits.view(-1, self.num_classes), labels)\n",
    "\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss2 = loss_fct(logits2.view(-1, 2), labels_types.view(-1))\n",
    "                loss = loss1 + loss2\n",
    "                # loss = loss_function(logits, labels)\n",
    "\n",
    "                wandb.log({\"loss\": loss})\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            avg_loss = total_loss / len(dataloader)\n",
    "            print(f\"Epoch {epoch + 1}/{epochs} - Average Loss: {avg_loss}\")\n",
    "\n",
    "    def predict(self, texts, threshold=0.5):\n",
    "        input_ids, attention_mask = self.tokenize_texts(texts)\n",
    "        with torch.no_grad():\n",
    "            logits, _ = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(logits.logits)\n",
    "\n",
    "            predicted_labels = (probs > threshold).int()\n",
    "\n",
    "            zero_rows = predicted_labels.sum(dim=1) == 0\n",
    "            predicted_labels[zero_rows, -3] = 1\n",
    "\n",
    "        return predicted_labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_labels, gold_labels, subtask, techniques=None):\n",
    "    \"\"\"\n",
    "    Evaluates the predicted classes w.r.t. a gold file.\n",
    "    Metrics are:  macro_f1 nd micro_f1\n",
    "    :param pred_labels: a dictionary with predictions,\n",
    "    :param gold_labels: a dictionary with gold labels.\n",
    "    \"\"\"\n",
    "    pred_values, gold_values = pred_labels, gold_labels\n",
    "\n",
    "    # We are scoring for subtask 1B\n",
    "    if subtask == \"1B\":\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        mlb.fit([techniques])\n",
    "        gold_values = mlb.transform(gold_values)\n",
    "        # pred_values = mlb.transform(pred_values)\n",
    "\n",
    "    micro_f1 = f1_score(gold_values, pred_values, average=\"micro\")\n",
    "    macro_f1 = f1_score(gold_values, pred_values, average=\"macro\")\n",
    "\n",
    "    return micro_f1, macro_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(hyper_params: dict):\n",
    "    # create output directories if they don't exist\n",
    "    OUTPUT_DIR = \"output/task1B\"\n",
    "\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    wandb.init(\n",
    "        project=\"araieval_subtaskB\",\n",
    "        config=hyper_params,\n",
    "    )\n",
    "\n",
    "    train_file = \"task1B_train.jsonl\"\n",
    "    test_file = \"task1B_dev.jsonl\"\n",
    "\n",
    "    # check if the data files exist\n",
    "    if not os.path.exists(train_file):\n",
    "        raise FileNotFoundError(f\"File not found: {train_file}\")\n",
    "    if not os.path.exists(test_file):\n",
    "        raise FileNotFoundError(f\"File not found: {test_file}\")\n",
    "\n",
    "    # read the data\n",
    "    df = pd.read_json(train_file, lines=True)\n",
    "\n",
    "    unique_labels = set()\n",
    "    for label_list in df[\"labels\"]:\n",
    "        unique_labels.update(label_list)\n",
    "\n",
    "    train_texts, train_labels, train_types, trains_ids = read_data_1b(\n",
    "        train_file,\n",
    "        preprocessing=hyper_params[\"preprocessing\"],\n",
    "        unique_labels=unique_labels,\n",
    "    )\n",
    "    test_texts, test_labels, test_types, test_ids = read_data_1b(\n",
    "        test_file,\n",
    "        preprocessing=hyper_params[\"preprocessing\"],\n",
    "        unique_labels=unique_labels,\n",
    "    )\n",
    "\n",
    "    num_classes = len(unique_labels)\n",
    "\n",
    "    # instantiate a model\n",
    "    model_name = hyper_params[\"model_name\"]\n",
    "    classifier = BertMultilabelClassifier(model_name, num_classes)\n",
    "\n",
    "    classifier.train(\n",
    "        texts=train_texts,\n",
    "        labels=train_labels,\n",
    "        labels_types=train_types,\n",
    "        batch_size=hyper_params[\"batch_size\"],\n",
    "        epochs=hyper_params[\"epochs\"],\n",
    "        learning_rate=hyper_params[\"learning_rate\"],\n",
    "    )\n",
    "\n",
    "    predicted_labels, probabilities = classifier.predict(test_texts)\n",
    "    micro_f1, macro_f1 = evaluate(\n",
    "        predicted_labels.cpu().tolist(), test_labels, subtask=\"1A\"\n",
    "    )\n",
    "    print(\"micro-F1={:.4f}\\tmacro-F1={:.4f}\".format(micro_f1, macro_f1))\n",
    "    # micro_f1, macro_f1 = float(0), float(0)\n",
    "\n",
    "    run_name = wandb.run.name\n",
    "\n",
    "    def find_indices(list_to_check, item_to_find):\n",
    "        return [idx for idx, value in enumerate(list_to_check) if value == item_to_find]\n",
    "\n",
    "    with open(f\"{OUTPUT_DIR}/task1B_output_{run_name}.tsv\", \"w\") as file:\n",
    "        file.write(\"id\\tlabel\\n\")\n",
    "        for id, pred in zip(test_ids, predicted_labels.cpu().tolist()):\n",
    "            r = find_indices(pred, 1)\n",
    "\n",
    "            label = [list(unique_labels)[item] for item in r]\n",
    "\n",
    "            file.write(str(id) + \"\\t\" + \",\".join(label) + \"\\n\")\n",
    "\n",
    "            # file.write(str(id)+\"\\t\"+str(label)+\"\\n\")\n",
    "\n",
    "    return {\"micro_f1\": micro_f1, \"macro_f1\": macro_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model_name\": \"UBC-NLP/MARBERT\",\n",
    "    \"loss_type\": \"bce\",\n",
    "    \"model_archi\": \"multitask\",\n",
    "    \"seed\": 42,\n",
    "    \"learning_rate\": 1e-05,\n",
    "    \"epochs\": 5,\n",
    "    \"batch_size\": 8,\n",
    "    \"preprocessing\": False,\n",
    "    \"stopwords_size\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set the seed for random number generation in Python's random, numpy, and torch libraries.\n",
    "    If a GPU is available, it also sets the seed for random number generation on the GPU.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(params[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtaqiyeddine\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/teb/Transformers-for-Propaganda-Detection/notebooks/wandb/run-20240923_052045-cug4us6r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/taqiyeddine/araieval_subtaskB/runs/cug4us6r' target=\"_blank\">classic-dragon-95</a></strong> to <a href='https://wandb.ai/taqiyeddine/araieval_subtaskB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/taqiyeddine/araieval_subtaskB' target=\"_blank\">https://wandb.ai/taqiyeddine/araieval_subtaskB</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/taqiyeddine/araieval_subtaskB/runs/cug4us6r' target=\"_blank\">https://wandb.ai/taqiyeddine/araieval_subtaskB/runs/cug4us6r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 2427line [00:00, 17236.98line/s]\n",
      "Processing: 259line [00:00, 16702.67line/s]\n",
      "Some weights of BertForMultitaskClassification were not initialized from the model checkpoint at UBC-NLP/MARBERT and are newly initialized: ['classifier.bias', 'classifier.weight', 'classifier2.bias', 'classifier2.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/teb/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Running epoch :  20%|██        | 1/5 [00:24<01:37, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Average Loss: 0.551929550833608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running epoch :  40%|████      | 2/5 [00:48<01:12, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Average Loss: 0.27655986387674747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running epoch :  60%|██████    | 3/5 [01:13<00:48, 24.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Average Loss: 0.22352978567543783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running epoch :  80%|████████  | 4/5 [01:37<00:24, 24.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Average Loss: 0.21284728085524157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running epoch : 100%|██████████| 5/5 [02:01<00:00, 24.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Average Loss: 0.19957419477501198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro-F1=0.4595\tmacro-F1=0.0337\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>██▅▃▄▂▂▃▂▂▂▂▂▄▂▂▂▂▂▁▁▁▁▁▁▁▂▂▁▄▁▁▁▁▁▁▂▁▁▁</td></tr><tr><td>macro_f1</td><td>▁</td></tr><tr><td>micro_f1</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.14814</td></tr><tr><td>macro_f1</td><td>0.03372</td></tr><tr><td>micro_f1</td><td>0.45953</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-dragon-95</strong> at: <a href='https://wandb.ai/taqiyeddine/araieval_subtaskB/runs/cug4us6r' target=\"_blank\">https://wandb.ai/taqiyeddine/araieval_subtaskB/runs/cug4us6r</a><br/> View project at: <a href='https://wandb.ai/taqiyeddine/araieval_subtaskB' target=\"_blank\">https://wandb.ai/taqiyeddine/araieval_subtaskB</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240923_052045-cug4us6r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = pipeline(params)\n",
    "wandb.log(metrics)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
